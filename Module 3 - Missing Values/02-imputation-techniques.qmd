---
title: "Imputing Missing Values"
date: '2025-10-07'
engine: knitr
type: slides
categories:
- slides
- Week04
format:
  revealjs:
    transition: slide
    background-transition: fade
    navigation-mode: vertical
    logo: ../../N.svg
    includes:
      in_header: ../../header.html
---


```{r setup, message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(naniar)
library(mice)
library(purrr)
library(NHANES)
```

```{r create-data, echo = FALSE}
set.seed(202509)
df <- tibble(
  id    = 1:20,
  age   = sample(c(18:70, NA), 20, replace = TRUE),
  income = sample(c(10^5*(3:6), NA), 20, replace = TRUE),
  score  = sample(c(1:5, NA, NA), 20, replace = TRUE),
  group  = sample(c("A", "B", NA), 20, replace = TRUE)
)
```

# How do we 'fix' datasets with missing values?

# Approach (1): Complete Case Analysis

- Remove samples with missing values: `na.omit`, `na_drop` 

- Use with extreme caution! This is not recommended!!

```{r}
NHANES |> drop_na() |> dim()
```

- None of the NHANES data is complete.

- Generally, this is a very naive strategy 


# Approach (2): Impute with mean

Impute missing values with mean - Again, not recommended!

```{r}
# Mean imputation (bad practice!)
df_mean_imp <- df |>
  mutate(income_imp = if_else(is.na(income), mean(income, na.rm = TRUE), income)) 
```

```{r}
df_mean_imp |> ggplot(aes(x = income_imp)) + geom_histogram()
```
# Impact of Imputing with Mean

Mean is unaffected

```{r}
mean(df_mean_imp$income_imp)
mean(df_mean_imp$income, na.rm = TRUE)
```

SD is lowered - affects confidence intervals of estimates

```{r}
sd(df_mean_imp$income_imp)
sd(df_mean_imp$income, na.rm = TRUE)
```
# Example: Airquality

The `airquality` data is a(n ancient) data set in R capturing daily ozone, solar, wind and temperature measurements for 5 months   


Some of the ozone measurements are missing

```{r}
summary(airquality$Ozone)
```
Little's test shows that we reject the hypothesis of MCAR:

```{r}
mcar_test(airquality)
```
# 

How should we impute the Ozone values?

# Airquality overview


```{r}
library(GGally)
ggpairs(airquality)
```
# Model Ozone

```{r}
ozone_lm <- lm(Ozone~Temp + Wind, data = airquality)
summary(ozone_lm)
```

# Predict Ozone

Use a linear model to predict Ozone values based on covariates

```{r}
airquality_imp <- airquality |> mutate(
  Ozone_pred = predict(ozone_lm, newdata = airquality),
  imputed = is.na(Ozone),
  Ozone_imp = ifelse(is.na(Ozone), Ozone_pred, Ozone)
)
```


# Predict Ozone


```{r}
ggpairs(data = airquality_imp |> select(-Ozone_pred, -Ozone), 
        mapping = aes(colour = imputed)) 
```

# But - Variability is still affected

```{r}
mean(airquality$Ozone, na.rm=TRUE)
mean(airquality_imp$Ozone_imp)
```
```{r}
sd(airquality$Ozone, na.rm=TRUE)
sd(airquality_imp$Ozone_imp)
```
... increase by using samples from the linear model rather than predictions

# Idea for Predictive Mean Matching

Assume Y is variable with missing values, X are covariates with observed data

- Fit regression $Y = X\beta + \epsilon$.

- Predict missing values $\widehat{Y}_i$ from the model.

- Get predictions $\widehat{Y}_i$ for observed values $Y_i$. 

- Find nearest neighbors: for each missing value find $k$ closest neighbors based on prediction.

- Randomly draw one of the $k$ observed values $Y$ for the missing value.

# Multiple Imputation with `mice`

```{r airmice}
# Run multiple imputation
air_imp <- mice(airquality, m = 5, method = "pmm", seed = 202509)

# Completed datasets
completed_list <- complete(air_imp, "all") |> map(as_tibble)
```
All analysis are done on each of the data sets, results are then pooled across.

# Analyse airquality

```{r}
# Example: regression model
models <- map(completed_list, ~ lm(Ozone ~ Wind + Temp, data = .x))

# Pool results
pooled <- pool(models)
summary(pooled)
```

```{r}
summary(lm(Ozone ~ Wind + Temp, data = airquality))
```

# Choice of $k$

The choice of $k$ (number of neighbors) affects variability:

- Small $k$ result in closer matches, less variance.

- Larger $k$ result in more randomness, higher variance.


# Your Turn {background-color="#006666"}

Use the NHANES data to try out predictive matching for imputing missing values.

The variable `AgeMonths` in the data set is not recorded in one of the Survey years except for infants.
Use `mice` to use predictive matching to impute missing values in all of the age variables

For one of the complete datasets, plot Age against the age at which the participant had their first baby (`Age1stBaby`). What do you find?

Set up a linear model of `AgeMonths` in `Age` and summarize the results. Do those results make sense?

# 

```{r miceNHANES}
library(NHANES)
imp_age <- mice(NHANES |> select(contains("Age")), m=5, method= "pmm", seed = 202510)


# Completed datasets
completed_list <- complete(imp_age, "all") |> map(as_tibble)

NHANES |> ggplot(aes(x = Age, y = Age1stBaby)) + geom_jitter() + facet_wrap(~Gender)

NHANES |> ggplot(aes(x = Age, y = Age1stBaby)) + geom_jitter() + facet_wrap(~Gender) + 
  geom_point(aes(colour = "Imputed"), data = completed_list[[1]])


# Now check: is AgeMonths about 12 x Age?
models <- map(completed_list, ~ lm(AgeMonths ~ Age, data = .x))

# Pool the models
pooled <- pool(models)
summary(pooled) # yes :)
```


# Your Turn {background-color="#006666"}

For the `NHANES` data:

1. Compare results of a (polynomial of degree 2) regression model (`BMI ~ Age + Gender`) under:
  - complete-case analysis,
  - mean imputation,
  - multiple imputation.

3. Discuss: What assumptions are you making under each approach?


#

```{r}
bmi_complete <- lm(BMI ~ poly(Age,2)*Gender, data = NHANES)
dframe <- data.frame(expand.grid(Age = 0:80, Gender=c("female", "male")))
dframe$pred <- predict(bmi_complete, newdata = dframe)
NHANES |> ggplot(aes(x = Age, y = BMI)) + facet_wrap(~Gender) + 
  geom_point() + 
  geom_line(aes(x = Age, y = pred), colour = "#d00000", linewidth = 1.5, data = dframe)
```

```{r}
NHANES |> select(BMI, Age) |> summary()

```

# Conclusion

  - Missingness can bias estimates if ignored.
- Mechanisms (MCAR/MAR/MNAR) determine what methods are valid.
- Na√Øve fixes are often misleading.
- Multiple imputation and likelihood-based methods are modern, principled approaches.
